<<<<<<< HEAD
deeplearing lab
=======
# ðŸ“˜ BÃ¡o cÃ¡o bÃ i táº­p: Máº¡ng Neural Ä‘Æ¡n giáº£n báº±ng NumPy trÃªn MNIST

## 1. ðŸ“ Äá» bÃ i

XÃ¢y dá»±ng vÃ  huáº¥n luyá»‡n má»™t máº¡ng neural Ä‘Æ¡n giáº£n **báº±ng thÆ° viá»‡n NumPy**, khÃ´ng sá»­ dá»¥ng cÃ¡c framework huáº¥n luyá»‡n cao cáº¥p nhÆ° Keras, PyTorch,... Ä‘á»ƒ phÃ¢n loáº¡i chá»¯ sá»‘ viáº¿t tay tá»« **táº­p dá»¯ liá»‡u MNIST**.

YÃªu cáº§u:
- Tá»± cÃ i Ä‘áº·t mÃ´ hÃ¬nh (fully-connected feedforward neural network)
- Huáº¥n luyá»‡n báº±ng thuáº­t toÃ¡n lan truyá»n ngÆ°á»£c (backpropagation)
- Thá»­ nghiá»‡m vá»›i nhiá»u cáº¥u hÃ¬nh siÃªu tham sá»‘ (hyperparameters)
- TrÃ¬nh bÃ y káº¿t quáº£ vÃ  phÃ¢n tÃ­ch

---

## 2. ðŸ§  MÃ´ hÃ¬nh Ä‘á» xuáº¥t

- Máº¡ng neural gá»“m:
  - **1 lá»›p áº©n** (kÃ­ch thÆ°á»›c thay Ä‘á»•i)
  - HÃ m kÃ­ch hoáº¡t: `ReLU` hoáº·c `Sigmoid`
  - Lá»›p output dÃ¹ng `Softmax`
- Dá»¯ liá»‡u Ä‘áº§u vÃ o:
  - áº¢nh MNIST kÃ­ch thÆ°á»›c 28Ã—28 â†’ flatten thÃ nh vector 784 chiá»u
- HÃ m máº¥t mÃ¡t:
  - `Cross-entropy`
- Huáº¥n luyá»‡n:
  - Dá»±a trÃªn lan truyá»n xuÃ´i (forward), lan truyá»n ngÆ°á»£c (backward), vÃ  cáº­p nháº­t báº±ng `SGD` Ä‘Æ¡n giáº£n.

---

## 3. âš™ï¸ CÃ¡c siÃªu tham sá»‘ thá»­ nghiá»‡m

Project cháº¡y thá»­ nghiá»‡m trÃªn 5 cáº¥u hÃ¬nh khÃ¡c nhau cá»§a:
- `batch_size`
- `learning_rate`
- `sá»‘ lÆ°á»£ng neuron lá»›p áº©n`
- `activation function`

| Batch Size | Learning Rate | Hidden Size | Activation | Mean Acc (%) | Std Acc (%) |
|------------|----------------|-------------|-------------|---------------|---------------|
| 32         | 0.1            | 16          | ReLU        | 94.97         | 0.30          |
| 16         | 0.2            | 64          | Sigmoid     | 97.21         | 0.11          |
| 64         | 0.3            | 32          | ReLU        | 96.45         | 0.18          |
| 32         | 0.4            | 128         | Sigmoid     | 97.60         | 0.06          |
| 16         | 0.5            | 32          | ReLU        | 94.46         | 0.41          |

> Káº¿t quáº£ lÃ  **trung bÃ¬nh accuracy** vÃ  **Ä‘á»™ lá»‡ch chuáº©n** trÃªn 5 láº§n cháº¡y cho má»—i cáº¥u hÃ¬nh.

---

## 4. ðŸ“Š Nháº­n xÃ©t

- MÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng khÃ¡ tá»‘t trÃªn MNIST, Ä‘áº¡t Ä‘áº¿n **97.6% Ä‘á»™ chÃ­nh xÃ¡c** dÃ¹ chá»‰ dÃ¹ng NumPy.
- CÃ¡c mÃ´ hÃ¬nh sá»­ dá»¥ng **Sigmoid vá»›i hidden layer lá»›n** (nhÆ° 128) vÃ  **learning rate vá»«a pháº£i (0.4)** cho káº¿t quáº£ tá»‘t nháº¥t.
- `ReLU` cho tá»‘c Ä‘á»™ há»™i tá»¥ nhanh, nhÆ°ng vá»›i learning rate cao (`0.5`) thÃ¬ dá»… bá»‹ máº¥t á»•n Ä‘á»‹nh, nháº¥t lÃ  vá»›i máº¡ng nhá».
- Äá»™ lá»‡ch chuáº©n nhá» (táº§m 0.1â€“0.4%) cho tháº¥y káº¿t quáº£ khÃ¡ á»•n Ä‘á»‹nh qua nhiá»u láº§n cháº¡y.

---

## 5. ðŸ“ File ná»™p

- `src.py`: mÃ£ nguá»“n hoÃ n chá»‰nh (training + evaluation)
- `README.md`: bÃ¡o cÃ¡o tá»•ng há»£p káº¿t quáº£

---

## 6. ðŸ”§ CÃ¡ch cháº¡y

### CÃ i Ä‘áº·t thÆ° viá»‡n
```bash
pip install numpy tensorflow tabulate
>>>>>>> e401e39 (Upload folder LAB_01)
